---
description: >-
  Explore how software design choices reflect values—and why developers must
  make ethical decisions that respect users, communities, and society.
---

# 430.2 Ethical and social responsibilities

### TL;DR

Software engineers make decisions that affect how people live, work, and interact. Ethical responsibilities go beyond laws, including respecting user autonomy, reducing harm, addressing bias, and designing software that supports trust, fairness, and well-being. In this topic, you’ll explore how ethical questions shape software design and deployment in a connected world.

### Targets

In this topic, students learn to:

* Identify common ethical challenges in software engineering, including bias, manipulation, and lack of transparency
* Explain how consent, fairness, and autonomy influence software design choices
* Evaluate the consequences of unethical design through real-world case studies
* Compare ethical frameworks and apply them to software-related dilemmas
* Reflect on the developer’s role in making responsible design decisions

### Why ethics matters in software

Not all harm caused by software is illegal. Sometimes software does exactly what it was programmed to do—but in a way that undermines user trust, exploits behaviour, or has unintended consequences. That’s where ethics comes in.

Ethical responsibilities involve asking:

* _Should we collect this data?_
* _Is this algorithm fair?_
* _Are users being tricked, excluded, or harmed?_

When developers ignore these questions, the results can include loss of trust, reputational damage, and harm to vulnerable users.

### Consent and autonomy

Respect for user autonomy is a core ethical principle. Users should have meaningful control over their data collection, use, and sharing. Ethical design requires informed consent, not just burying permissions in long terms and conditions.

#### Example

Many apps request access to the microphone, location, and contacts, sometimes without an apparent reason. Ethical design would explain why the data is needed and let users opt in or out easily.

### Algorithmic bias and fairness

Algorithms are not neutral. They can replicate and even amplify discrimination when trained on biased data or designed without diverse input.

Examples of algorithmic bias:

* Facial recognition software that performs poorly on people with darker skin tones
* Job application filters that unfairly disadvantage women or minority groups
* Loan approval systems that penalise postcodes based on historical data

Ethical developers must test for and mitigate bias, include diverse perspectives, and build explainable AI that makes decisions transparently.

### Dark patterns and manipulation

Dark patterns are deceptive design techniques that trick users into doing things they didn’t intend, like subscribing without realising it, or giving up privacy without understanding.

Examples include:

* Making the “Accept all cookies” button big and green while hiding the “Decline” link
* Requiring users to navigate five screens to cancel a subscription
* Auto-opting users into marketing emails

These patterns are unethical because they exploit user habits and reduce informed choice.

### The ethics of persuasion and influence

Software can change behaviour, sometimes for good, but sometimes in manipulative ways.

Ethical questions include:

* Is this app helping users reach _their_ goals, or manipulating them for engagement?
* Is the software designed to support healthy behaviour, or exploit attention?
* Are notifications respectful, or addictive?

#### Example

A mindfulness app might ethically encourage daily reflection. A game app that sends hourly push notifications to create a habit loop may cross the line into exploitation.

### Ethical decision-making frameworks

While there is no single ethical rulebook for software, developers can use ethical frameworks to guide their thinking. For example:

<table><thead><tr><th width="232.94140625">Framework</th><th>Guiding question</th></tr></thead><tbody><tr><td>Utilitarianism</td><td>What action produces the greatest good?</td></tr><tr><td>Deontology</td><td>What is my duty, regardless of outcome?</td></tr><tr><td>Virtue ethics</td><td>What kind of person/designer should I be?</td></tr><tr><td>Rights-based ethics</td><td>Does this respect user rights and freedoms?</td></tr></tbody></table>

These frameworks can help teams evaluate difficult trade-offs and make decisions that align with their values.

### Case study: TikTok and ethical design concerns

TikTok has been criticised for several ethically questionable practices:

* Collecting large amounts of user data, including facial data and biometric identifiers
* Using algorithms that may promote harmful content
* Making it difficult to delete accounts or understand what data is collected

These issues raise questions about user consent, data handling, algorithmic transparency, and the manipulation of user attention.
